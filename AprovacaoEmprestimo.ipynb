{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IibT18yidbNt"
   },
   "source": [
    "# **Machine Learning (Classificação) - Aprovação de Empréstimos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrMWPdrgXGOC"
   },
   "source": [
    "### Dados da coluna:\n",
    "\n",
    " Este conjunto de dados fornece informações sobre as características dos requerentes de empréstimos e a sua avaliação de risco. Ele inclui informações sobre vários atributos dos solicitantes de empréstimo, incluindo detalhes demográficos, status financeiro, histórico de emprego e status de propriedade. O conjunto de dados inclui características numéricas e categóricas, tornando-o adequado para diversas abordagens analíticas.\n",
    "\n",
    " Principais características:\n",
    "\n",
    "Id: Identificador exclusivo para cada solicitante de empréstimo.\n",
    "\n",
    "Rendimento: O nível de rendimento do requerente.\n",
    "\n",
    "Idade: Idade do candidato.\n",
    "\n",
    "Experiência: Anos de experiência profissional.\n",
    "\n",
    "Casado/Solteiro: Estado civil do requerente.\n",
    "\n",
    "House_Ownership: Indica se o requerente possui ou aluga uma casa.\n",
    "\n",
    "Car_Ownership: Indica se o requerente é proprietário de um carro.\n",
    "\n",
    "Profissão: Ocupação ou profissão do candidato.\n",
    "\n",
    "CIDADE: Cidade de residência do requerente.\n",
    "\n",
    "ESTADO: Estado de residência do requerente.\n",
    "\n",
    "CURRENT_JOB_YRS: Duração do emprego no emprego atual.\n",
    "\n",
    "CURRENT_HOUSE_YRS: Duração da residência na casa atual.\n",
    "\n",
    "Risk_Flag: Indicador binário de risco de empréstimo, onde 1 representa um candidato de risco sinalizado e 0 representa um candidato não arriscado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0gKmtDSdG5g"
   },
   "source": [
    "## **Importando as Bibliotecas e Carregando o Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "executionInfo": {
     "elapsed": 22780,
     "status": "ok",
     "timestamp": 1717776135122,
     "user": {
      "displayName": "Diogo Monteiro",
      "userId": "10124739780104522117"
     },
     "user_tz": 180
    },
    "id": "o0NXDVPGXFoI",
    "outputId": "6aeb4aae-4e02-462f-d7c5-2c24f7b60f6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# ignorando avisos\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Estilo Dark nos gráficos do Matplotlib e Seaborn\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Carregando os dados \n",
    "df = pd.read_json('/Users/diogomonteiro/loan_approval_dataset 3.json')\n",
    "\n",
    "# Análisando os 5 primeiros dados\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1717776992775,
     "user": {
      "displayName": "Diogo Monteiro",
      "userId": "10124739780104522117"
     },
     "user_tz": 180
    },
    "id": "L9YWB3FPfKwC",
    "outputId": "d3fcf25d-9eb8-4007-888e-6b66ebbd19f3"
   },
   "outputs": [],
   "source": [
    "# Analisando o tamanho dos dados, xxxxx linhas, xx colunas\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Análise Exploratória das Variáveis Categóricas e Numéricas'**\n",
    "\n",
    "Nesta análise temos 2 objetivos:\n",
    "\n",
    "1 - Conhecer as variáveis alvo (Risk_Flag) está relacionado com as outras variáveis.\n",
    "\n",
    "2 - Iremos avaliar as variáveis categóricas para conhecimento dos dados e descartar variáveis que não fazem sentido.\n",
    "\n",
    "3 - Conhecer as variáveis numéricas.\n",
    "\n",
    "4 - Realizar uma análise estatística nas variáveis para o futuros tratamentos. Iremos avaliar média, mediana, moda, desvio padrão correlações, outliers, distruição dos dados, etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df\n",
    "df2['Risk_Flag'] = df['Risk_Flag'].astype(str)\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise(dados):\n",
    "    for i in dados.columns:\n",
    "        if dados[i].dtypes == 'object':\n",
    "            print(f'\\n Nome da coluna: {dados[i].name}\\n')\n",
    "            print(f'\\n Tipo da coluna: {dados[i].dtypes}\\n')\n",
    "            print(f'\\n Analisando os dados nulos: {dados[i].isnull().sum()}\\n')\n",
    "            plt.figure(figsize=(16,6))\n",
    "            plt.title(dados[i].name)\n",
    "            sns.countplot(data = dados, x = dados[i], hue = 'Risk_Flag')\n",
    "            plt.show();\n",
    "\n",
    "        else:\n",
    "            print(f'\\n Nome da coluna: {dados[i].name}\\n')\n",
    "            print(f'\\n Tipo da coluna: {dados[i].dtypes}\\n')\n",
    "            print(f'\\n Analisando os dados nulos: {dados[i].isnull().sum()}\\n')\n",
    "            print(f'\\n Analisando os quartis:\\n\\n{dados[i].describe()}\\n')\n",
    "            plt.title(dados[i].name)\n",
    "            sns.boxplot(data = dados[i])\n",
    "            plt.show();\n",
    "analise(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Profession']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['CITY']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['STATE']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= df.drop(['Id','Profession', 'STATE','CITY'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1717767959531,
     "user": {
      "displayName": "Diogo Monteiro",
      "userId": "10124739780104522117"
     },
     "user_tz": 180
    },
    "id": "zKYF3gJNHZTj"
   },
   "outputs": [],
   "source": [
    "'''df1 = pd.get_dummies(df,columns=['House_Ownership', 'Profession', 'STATE'])\n",
    "df1[['House_Ownership_norent_noown', 'House_Ownership_owned',\n",
    "       'House_Ownership_rented', 'Profession_Air_traffic_controller',\n",
    "       'Profession_Analyst', 'Profession_Architect', 'Profession_Army_officer',\n",
    "       'Profession_Artist', 'Profession_Aviator',\n",
    "       'Profession_Biomedical_Engineer', 'Profession_Chartered_Accountant',\n",
    "       'Profession_Chef', 'Profession_Chemical_engineer',\n",
    "       'Profession_Civil_engineer', 'Profession_Civil_servant',\n",
    "       'Profession_Comedian', 'Profession_Computer_hardware_engineer',\n",
    "       'Profession_Computer_operator', 'Profession_Consultant',\n",
    "       'Profession_Dentist', 'Profession_Design_Engineer',\n",
    "       'Profession_Designer', 'Profession_Drafter', 'Profession_Economist',\n",
    "       'Profession_Engineer', 'Profession_Fashion_Designer',\n",
    "       'Profession_Financial_Analyst', 'Profession_Firefighter',\n",
    "       'Profession_Flight_attendant', 'Profession_Geologist',\n",
    "       'Profession_Graphic_Designer', 'Profession_Hotel_Manager',\n",
    "       'Profession_Industrial_Engineer', 'Profession_Lawyer',\n",
    "       'Profession_Librarian', 'Profession_Magistrate',\n",
    "       'Profession_Mechanical_engineer', 'Profession_Microbiologist',\n",
    "       'Profession_Official', 'Profession_Petroleum_Engineer',\n",
    "       'Profession_Physician', 'Profession_Police_officer',\n",
    "       'Profession_Politician', 'Profession_Psychologist',\n",
    "       'Profession_Scientist', 'Profession_Secretary',\n",
    "       'Profession_Software_Developer', 'Profession_Statistician',\n",
    "       'Profession_Surgeon', 'Profession_Surveyor',\n",
    "       'Profession_Technical_writer', 'Profession_Technician',\n",
    "       'Profession_Technology_specialist', 'Profession_Web_designer',\n",
    "       'STATE_Andhra_Pradesh', 'STATE_Assam', 'STATE_Bihar',\n",
    "       'STATE_Chandigarh', 'STATE_Chhattisgarh', 'STATE_Delhi',\n",
    "       'STATE_Gujarat', 'STATE_Haryana', 'STATE_Himachal_Pradesh',\n",
    "       'STATE_Jammu_and_Kashmir', 'STATE_Jharkhand', 'STATE_Karnataka',\n",
    "       'STATE_Kerala', 'STATE_Madhya_Pradesh', 'STATE_Maharashtra',\n",
    "       'STATE_Manipur', 'STATE_Mizoram', 'STATE_Odisha', 'STATE_Puducherry',\n",
    "       'STATE_Punjab', 'STATE_Rajasthan', 'STATE_Sikkim', 'STATE_Tamil_Nadu',\n",
    "       'STATE_Telangana', 'STATE_Tripura', 'STATE_Uttar_Pradesh',\n",
    "       'STATE_Uttar_Pradesh[5]', 'STATE_Uttarakhand', 'STATE_West_Bengal']] = df1[['House_Ownership_norent_noown', 'House_Ownership_owned',\n",
    "       'House_Ownership_rented', 'Profession_Air_traffic_controller',\n",
    "       'Profession_Analyst', 'Profession_Architect', 'Profession_Army_officer',\n",
    "       'Profession_Artist', 'Profession_Aviator',\n",
    "       'Profession_Biomedical_Engineer', 'Profession_Chartered_Accountant',\n",
    "       'Profession_Chef', 'Profession_Chemical_engineer',\n",
    "       'Profession_Civil_engineer', 'Profession_Civil_servant',\n",
    "       'Profession_Comedian', 'Profession_Computer_hardware_engineer',\n",
    "       'Profession_Computer_operator', 'Profession_Consultant',\n",
    "       'Profession_Dentist', 'Profession_Design_Engineer',\n",
    "       'Profession_Designer', 'Profession_Drafter', 'Profession_Economist',\n",
    "       'Profession_Engineer', 'Profession_Fashion_Designer',\n",
    "       'Profession_Financial_Analyst', 'Profession_Firefighter',\n",
    "       'Profession_Flight_attendant', 'Profession_Geologist',\n",
    "       'Profession_Graphic_Designer', 'Profession_Hotel_Manager',\n",
    "       'Profession_Industrial_Engineer', 'Profession_Lawyer',\n",
    "       'Profession_Librarian', 'Profession_Magistrate',\n",
    "       'Profession_Mechanical_engineer', 'Profession_Microbiologist',\n",
    "       'Profession_Official', 'Profession_Petroleum_Engineer',\n",
    "       'Profession_Physician', 'Profession_Police_officer',\n",
    "       'Profession_Politician', 'Profession_Psychologist',\n",
    "       'Profession_Scientist', 'Profession_Secretary',\n",
    "       'Profession_Software_Developer', 'Profession_Statistician',\n",
    "       'Profession_Surgeon', 'Profession_Surveyor',\n",
    "       'Profession_Technical_writer', 'Profession_Technician',\n",
    "       'Profession_Technology_specialist', 'Profession_Web_designer',\n",
    "       'STATE_Andhra_Pradesh', 'STATE_Assam', 'STATE_Bihar',\n",
    "       'STATE_Chandigarh', 'STATE_Chhattisgarh', 'STATE_Delhi',\n",
    "       'STATE_Gujarat', 'STATE_Haryana', 'STATE_Himachal_Pradesh',\n",
    "       'STATE_Jammu_and_Kashmir', 'STATE_Jharkhand', 'STATE_Karnataka',\n",
    "       'STATE_Kerala', 'STATE_Madhya_Pradesh', 'STATE_Maharashtra',\n",
    "       'STATE_Manipur', 'STATE_Mizoram', 'STATE_Odisha', 'STATE_Puducherry',\n",
    "       'STATE_Punjab', 'STATE_Rajasthan', 'STATE_Sikkim', 'STATE_Tamil_Nadu',\n",
    "       'STATE_Telangana', 'STATE_Tripura', 'STATE_Uttar_Pradesh',\n",
    "       'STATE_Uttar_Pradesh[5]', 'STATE_Uttarakhand', 'STATE_West_Bengal']].astype('int64')'''\n",
    "df1 = pd.get_dummies(df,columns=['House_Ownership'])\n",
    "df1[['House_Ownership_norent_noown', 'House_Ownership_owned',\n",
    "       'House_Ownership_rented']] = df1[['House_Ownership_norent_noown', 'House_Ownership_owned',\n",
    "       'House_Ownership_rented']].astype('int64')\n",
    "df1['Married/Single'].replace({'single': 0, 'married':1},inplace=True)\n",
    "df1['Car_Ownership'].replace({'yes': 1, 'no': 0}, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1717767959532,
     "user": {
      "displayName": "Diogo Monteiro",
      "userId": "10124739780104522117"
     },
     "user_tz": 180
    },
    "id": "dQLGudksHZP7"
   },
   "outputs": [],
   "source": [
    "df1 = df1.drop('CITY', axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1717767959532,
     "user": {
      "displayName": "Diogo Monteiro",
      "userId": "10124739780104522117"
     },
     "user_tz": 180
    },
    "id": "wHd0SC1uHZKF"
   },
   "source": [
    "### **Resposta:**\n",
    "\n",
    "Analisando os gráficos podemos ver que não temos outliers e não temos dados nulos, também vimos que a coluna City tem bastantes variáveis, por isso quando ultilizarmos get_dummies transformamos os dados categóricos em numéricos vamos ter muitas colunas.\n",
    "Então vamos dividir os dados com a coluna City, e sem a coluna City, e vamos ver com o algoritimo se sai.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.drop(['Profession','STATE','Risk_Flag'],axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.get_dummies(df,columns=['Married/Single',\n",
    "       'House_Ownership', 'Car_Ownership', 'Profession', 'CITY', 'STATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop('Risk_Flag',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df3.columns:\n",
    "    if df3[i].dtypes == 'objetic':\n",
    "        df3[i] = df3[i].astype('int64')\n",
    "df3.dtypes        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler().fit_transform(df3)\n",
    "scaler_x1 = pd.DataFrame(scaler1)\n",
    "scaler_x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit_transform(x)\n",
    "scaler_x = pd.DataFrame(scaler)\n",
    "scaler_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1.Risk_Flag.astype('int64')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino,x_teste,y_treino,y_teste = train_test_split(scaler_x,y, test_size = 0.3, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {\n",
    "    'naive_bayes': GaussianNB(),\n",
    "    'logistic': LogisticRegression(tol=0.0001,C=1,solver='lbfgs',max_iter=600,random_state= 0,),\n",
    "    'random': RandomForestClassifier(n_estimators=100,criterion='gini',random_state=0,max_depth=3),\n",
    "    'arvore': DecisionTreeClassifier(criterion='gini',random_state=0,max_depth=3),\n",
    "    'knn': KNeighborsClassifier(n_neighbors=7, metric='minkowski',p=5,),\n",
    "    'xgboost': XGBClassifier()\n",
    "}\n",
    "\n",
    "class machine():\n",
    "\n",
    "    def __init__(self,modelos,x_treino,x_teste,y_treino,y_teste):\n",
    "        self.modelos = modelos\n",
    "        self.x_treino = x_treino\n",
    "        self.x_teste = x_teste\n",
    "        self.y_treino = y_treino\n",
    "        self.y_teste = y_teste\n",
    "        self.modelos_score = []\n",
    "\n",
    "    def relatorioML(self):\n",
    "\n",
    "        \n",
    "        \n",
    "        for nome, model in self.modelos.items():\n",
    "\n",
    "            \n",
    "            # Ajustar o modelo com os dados de treino\n",
    "            model.fit(self.x_treino, self.y_treino)\n",
    "            \n",
    "            # Previsões para o conjunto de treino e teste\n",
    "            previsor_treino = model.predict(self.x_treino)\n",
    "            previsor_teste = model.predict(self.x_teste)\n",
    "            \n",
    "            # Calcular a acurácia para treino e teste\n",
    "            acuracia_treino = accuracy_score(self.y_treino, previsor_treino)\n",
    "            acuracia_teste = accuracy_score(self.y_teste, previsor_teste)\n",
    "            \n",
    "            # Validação cruzada\n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "            \n",
    "            resul = cross_val_score(model, self.x_treino, self.y_treino, cv=kf,n_jobs=-1)\n",
    "\n",
    "            resul1 = cross_val_score(model, self.x_teste, self.y_teste, cv=kf,n_jobs=-1)\n",
    "\n",
    "            resul_val_cruzada = round(resul.mean() * 100, 2)\n",
    "            \n",
    "            resul_val_cruzada1 = round(resul1.mean() * 100, 2)\n",
    "            \n",
    "            resultado_treino = round(model.score(self.x_treino,self.y_treino) * 100,2)\n",
    "            resultado_teste = round(model.score(self.x_teste,self.y_teste) * 100,2)\n",
    "        \n",
    "            self.modelos_score.append({'Modelos': nome, 'Acurácia Treino':'{:.2f}%'.format(resultado_treino),\n",
    "                                     'Acurácia Teste': '{:.2f}%'.format(resultado_teste),\n",
    "                                    'Acurácia validacao cruzada treino': '{:.2f}%'.format(resul_val_cruzada),\n",
    "                                      'Acurácia validacao cruzada teste': '{:.2f}%'.format(resul_val_cruzada1)})\n",
    "    \n",
    "        md = pd.DataFrame(self.modelos_score)\n",
    "\n",
    "        return md\n",
    "\n",
    "    def analiseML(self,modelo):\n",
    "        \n",
    "        previsor = modelo.predict(self.x_teste)\n",
    "        \n",
    "        previsor1 = modelo.predict(self.x_treino)\n",
    "\n",
    "\n",
    "        print(f'\\nTREINO')\n",
    "\n",
    "        print('---------------------------------------------------------------------------')\n",
    "        \n",
    "        print('\\n Acurácia treino: %.2f%%'%(accuracy_score(self.y_treino,previsor1)*100))\n",
    "\n",
    "        print('---------------------------------------------------------------------------')\n",
    "\n",
    "        print(f'\\nConfusão matrix: \\n{confusion_matrix(self.y_teste,previsor)}')\n",
    "\n",
    "        print('---------------------------------------------------------------------------')\n",
    "        \n",
    "        print(f'\\nClassificação: \\n\\n{classification_report(self.y_teste,previsor)}')\n",
    "\n",
    "        print('---------------------------------------------------------------------------\\n')\n",
    "\n",
    "        print(f'\\nTESTE')\n",
    "\n",
    "        print('---------------------------------------------------------------------------')\n",
    "        \n",
    "        print('\\n Acurácia teste: %.2f%%'%(accuracy_score(self.y_teste,previsor)*100))\n",
    "\n",
    "        print('---------------------------------------------------------------------------')\n",
    "        \n",
    "        print(f'\\nConfusão matrix: \\n{confusion_matrix(self.y_teste,previsor)}')\n",
    "\n",
    "        print('---------------------------------------------------------------------------')\n",
    "        \n",
    "        print(f'\\nClassificação: \\n\\n{classification_report(self.y_teste,previsor)}')\n",
    "\n",
    "        print('---------------------------------------------------------------------------')\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "Machine = machine(modelos,x_treino,x_teste,y_treino,y_teste)\n",
    "Machine.relatorioML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine.analiseML(modelos['naive_bayes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine.analiseML(modelos['logistic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine.analiseML(modelos['arvore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine.analiseML(modelos['random'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine.analiseML(modelos['knn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine.analiseML(modelos['xgboost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPWWFV2Zcned0+180ZbIFaF",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
